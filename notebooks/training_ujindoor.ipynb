{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "import sys \n",
    "sys.path.append('../scripts')\n",
    "from train import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "100%|██████████| 7773/7773 [00:07<00:00, 1074.50it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# load ujindoor datasets\n",
    "dataset_name_0_0 = \"ujindoorloc_building_0_floor_0\"\n",
    "train_loader, test_loader = load_dataset(name=dataset_name_0_0, k=5, batch_size = 32, train_ratio=0.8, test_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "for input in train_loader:\n",
    "    y = input.y\n",
    "    print(y.shape)\n",
    "    y = y.reshape(-1, 2)\n",
    "    # flag = y.shape[0] if y.shape[0] != 32 else None\n",
    "    # if flag:\n",
    "    #     print(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, name, train_loader, val_loader, epochs, lr=0.001, mae_loss=True):\n",
    "\n",
    "    accelerator = Accelerator()\n",
    "    # set optimizer and loss function \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # loss functions\n",
    "    mae = torch.nn.L1Loss()\n",
    "    mse = torch.nn.MSELoss()\n",
    "\n",
    "    # accelerator \n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(model, optimizer, train_loader, val_loader)\n",
    "\n",
    "\n",
    "    train_loss_epoch_mae = []\n",
    "    train_loss_epoch_mse = []\n",
    "    val_loss_epoch_mae = []\n",
    "    val_loss_epoch_mse = []\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # set model to train\n",
    "        model.train()\n",
    "\n",
    "        # collect losses\n",
    "        train_losses_mae = []\n",
    "        train_losses_mse = []\n",
    "\n",
    "        # set tqdm loop \n",
    "        loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "\n",
    "        for batch_idx, data in loop:\n",
    "\n",
    "            # get data\n",
    "            x, edge_attr, edge_index, batch_index, y = data.x, data.edge_attr, data.edge_index, data.batch, data.y\n",
    "\n",
    "            # reshape y\n",
    "            y = y.reshape(-1, 2)\n",
    "\n",
    "            # get output\n",
    "            output = model(x, edge_attr, edge_index, batch_index)\n",
    "\n",
    "            # calculate loss for x and y  dims\n",
    "            loss_mae = mae(output[:, :2], y[:, :2])\n",
    "            loss_mse = mse(output[:, :2], y[:, :2])\n",
    "\n",
    "            # collect losses\n",
    "            train_losses_mae.append(accelerator.gather(loss_mae.item()))\n",
    "            train_losses_mse.append(accelerator.gather(loss_mse.item()))\n",
    "\n",
    "            # zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backpropagate\n",
    "            if mae_loss:\n",
    "                accelerator.backward(loss_mae)\n",
    "            else:\n",
    "                accelerator.backward(loss_mse)\n",
    "\n",
    "            # optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # set description for tqdm\n",
    "            loop.set_description(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "            loop.set_postfix(loss_mae=loss_mae.item(), loss_mse=loss_mse.item())\n",
    "        \n",
    "        # get avg losses\n",
    "        avg_train_mae = np.mean(train_losses_mae)\n",
    "        avg_train_mse = np.mean(train_losses_mse)\n",
    "\n",
    "        # append to epoch losses\n",
    "        train_loss_epoch_mae.append(avg_train_mae)\n",
    "        train_loss_epoch_mse.append(avg_train_mse)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        model.eval()\n",
    "\n",
    "        # collect losses\n",
    "        val_losses_mae = []\n",
    "        val_losses_mse = []\n",
    "\n",
    "        # set tqdm loop\n",
    "        val_loop = tqdm(enumerate(val_loader), total=len(val_loader), leave=False)\n",
    "        \n",
    "        # torch no grad\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in val_loop:\n",
    "\n",
    "                # get data\n",
    "                x, edge_attr, edge_index, batch_index, y = data.x, data.edge_attr, data.edge_index, data.batch, data.y\n",
    "\n",
    "                # reshape y\n",
    "                y = y.reshape(-1, 2)\n",
    "\n",
    "                # get output\n",
    "                output = model(x, edge_attr, edge_index, batch_index)\n",
    "\n",
    "                # calculate loss for x and y dims\n",
    "                loss_mae = mae(output[:, :2], y[:, :2])\n",
    "                loss_mse = mse(output[:, :2], y[:, :2])\n",
    "\n",
    "                # collect losses\n",
    "                val_losses_mae.append(accelerator.gather(loss_mae.item()))\n",
    "                val_losses_mse.append(accelerator.gather(loss_mse.item()))\n",
    "\n",
    "                # set description for tqdm\n",
    "                val_loop.set_description(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "                val_loop.set_postfix(loss_mae=loss_mae.item(), loss_mse=loss_mse.item())\n",
    "\n",
    "        # get avg losses\n",
    "        avg_val_mae = np.mean(val_losses_mae)\n",
    "        avg_val_mse = np.mean(val_losses_mse)\n",
    "\n",
    "        # append to epoch losses\n",
    "        val_loss_epoch_mae.append(avg_val_mae)\n",
    "        val_loss_epoch_mse.append(avg_val_mse)\n",
    "\n",
    "    # wait for accelerator to finish\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    # save model if main process\n",
    "    if accelerator.is_main_process:\n",
    "        torch.save(model.state_dict(), f\"./weights/{name}.pt\")\n",
    "\n",
    "    # return losses\n",
    "    return train_loss_epoch_mae, train_loss_epoch_mse, val_loss_epoch_mae, val_loss_epoch_mse\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import notebook_launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Launching training on one GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m mae_loss \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m args \u001b[39m=\u001b[39m (model, name, train_loader, test_loader, epochs, lr, mae_loss)\n\u001b[0;32m----> 9\u001b[0m notebook_launcher(train, args, num_processes\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/accelerate/launchers.py:156\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLaunching training on CPU.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m function(\u001b[39m*\u001b[39;49margs)\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, name, train_loader, val_loader, epochs, lr, mae_loss)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m# set tqdm loop \u001b[39;00m\n\u001b[1;32m     29\u001b[0m loop \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(train_loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_loader), leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, data \u001b[39min\u001b[39;00m loop:\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m     \u001b[39m# get data\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     x, edge_attr, edge_index, batch_index, y \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_attr, data\u001b[39m.\u001b[39medge_index, data\u001b[39m.\u001b[39mbatch, data\u001b[39m.\u001b[39my\n\u001b[1;32m     36\u001b[0m     \u001b[39m# reshape y\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/accelerate/data_loader.py:394\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m     current_batch \u001b[39m=\u001b[39m send_to_device(current_batch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 394\u001b[0m next_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m batch_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip_batches:\n\u001b[1;32m    396\u001b[0m     \u001b[39myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/torch_geometric/data/dataset.py:258\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39mpresent).\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39mIn case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39mtuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39mbool, will return a subset of the dataset at the specified indices.\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, (\u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39minteger))\n\u001b[1;32m    255\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, Tensor) \u001b[39mand\u001b[39;00m idx\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m    256\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misscalar(idx))):\n\u001b[0;32m--> 258\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices()[idx])\n\u001b[1;32m    259\u001b[0m     data \u001b[39m=\u001b[39m data \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(data)\n\u001b[1;32m    260\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/kholy/GNNLoc/GNNLoc/notebooks/../scripts/dataset.py:127\u001b[0m, in \u001b[0;36mDataset.get\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m    124\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m    returns the idx-th data object\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(osp\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocessed_dir, \u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_data_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, idx)))\n\u001b[1;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1174\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1144\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/anaconda3/envs/GNN/lib/python3.9/site-packages/torch/serialization.py:1112\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1110\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1112\u001b[0m     storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[1;32m   1116\u001b[0m         wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m         _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from model import GCN\n",
    "model = GCN(3, 32, 128, 2, 2, 0.3)\n",
    "\n",
    "name = \"Building_0_floor_0_model_mae\"\n",
    "epochs = 500\n",
    "lr = 0.001\n",
    "mae_loss = True\n",
    "args = (model, name, train_loader, test_loader, epochs, lr, mae_loss)\n",
    "notebook_launcher(train, args, num_processes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
